{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:12:48.192679Z","iopub.execute_input":"2025-04-18T14:12:48.193055Z","iopub.status.idle":"2025-04-18T14:12:48.569285Z","shell.execute_reply.started":"2025-04-18T14:12:48.193021Z","shell.execute_reply":"2025-04-18T14:12:48.568187Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# STEP 1 : CREATE THE CLASS NODE FOR BUILDING THE TREE","metadata":{}},{"cell_type":"code","source":"class Node:\n    def __init__(self, predicted_class):\n        self.predicted_class = predicted_class\n        self.feature = None\n        self.threshold = None\n        self.left = None\n        self.right = None ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:17:44.499435Z","iopub.execute_input":"2025-04-18T14:17:44.500005Z","iopub.status.idle":"2025-04-18T14:17:44.505749Z","shell.execute_reply.started":"2025-04-18T14:17:44.499968Z","shell.execute_reply":"2025-04-18T14:17:44.504523Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# STEP 2 :  BEST SPLIT FUNCTION","metadata":{}},{"cell_type":"code","source":"#the goal of this function is to return best_feature and best_threshold \n\ndef best_split(X, y , n_classes, n_features):\n    m = len(y)\n    if m <= 1:\n        return None , None\n    #we need to find the gini for the parent node \n    num_parent = [np.sum(y==c) for c in range(n_classes)]\n    best_gini = 1.0 - sum([(n/m)**2 for n in num_parent])\n    best_threshold , best_feature = None , None \n\n    #we need to find the best_feature and the best threshold by looping through all the feeatures\n    #but we need to get the dataset in the best shape possible for this splitting \n    \n    for feature in range(n_features):\n        feature_values = X[:, feature]\n        threshold, classes = zip(*sorted(zip(feature_values, y))) #first time I'm learning about the *\n        \n        num_left = [0] * n_classes \n        num_right = num_parent.copy()\n        \n        for i in range(1, m):\n            c = classes[i-1]\n            num_left[c] += 1\n            num_right[c] -= 1\n            \n            #find the gini impurity for each partition and the weighted gini too \n            gini_left = 1 - sum([ (num_left[c]/i)**2 for c in range(n_classes)])\n            gini_right = 1 - sum([ (num_left[c]/(m-i))**2 for c in range(n_classes)])\n            gini = (((i * gini_left) + ((m-i)*gini_right)))/m\n            \n            if threshold[i-1] == threshold[i]:\n                continue\n                \n            if gini < best_gini:\n                best_gini = gini\n                best_feature = feature\n                best_threshold = (threshold[i] + threshold[i-1]) / 2\n    return best_threshold , best_feature\n                \n                \n                \n            \n\n            \n            \n\n            \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:56:48.908649Z","iopub.execute_input":"2025-04-18T14:56:48.909046Z","iopub.status.idle":"2025-04-18T14:56:48.919675Z","shell.execute_reply.started":"2025-04-18T14:56:48.909017Z","shell.execute_reply":"2025-04-18T14:56:48.918577Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# STEP 3 : Grow Tree using DFS","metadata":{}},{"cell_type":"code","source":"def grow_tree(X, y, depth=0 , max_depth= None, n_classes= None):\n    num_samples_per_class = [np.sum(y==i) for i in range(n_classes)]\n    predicted_class = np.argmax(num_samples_per_class)\n    node = Node(predicted_class = predicted_class)\n    \n    #just like in every depth first search and we need a base case \n    \n    if max_depth is not None and depth >= max_depth:\n        return node \n        \n    n_features = X.shape[1]\n    threshold , feature  = best_split(X, y, n_classes, n_features)\n\n    #another case we have to consider is if if feature return none\n    if feature is None :\n        return node\n    #splitting the dataset base on the best feature and best threshold \n    \n    indices_left = X[:, feature] < threshold\n    X_left, y_left = X[indices_left], y[indices_left]\n    X_right , y_right = X[~indices_left], y[~indices_left]\n\n    node.feature = feature\n    node.threshold = threshold\n    node.left = grow_tree(X_left, y_left, depth+1,max_depth , n_classes)\n    node.right =  grow_tree(X_right, y_right, depth+1,max_depth, n_classes)\n\n    return node\n    \n\n","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-04-18T16:13:24.501402Z","iopub.execute_input":"2025-04-18T16:13:24.501779Z","iopub.status.idle":"2025-04-18T16:13:24.509835Z","shell.execute_reply.started":"2025-04-18T16:13:24.501722Z","shell.execute_reply":"2025-04-18T16:13:24.508950Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Decision tree class","metadata":{}},{"cell_type":"code","source":"class DecisionTreeClassifier:\n    def __init__(self, max_depth=None):\n        self.max_depth = max_depth\n        self.root = None\n        self.n_classes = None\n\n    def fit(self, X, y):\n        self.n_classes = len(np.unique(y))\n        self.root = grow_tree(X, y, max_depth=self.max_depth, n_classes=self.n_classes)\n        return self\n\n    def predict(self, X):\n        return np.array([self._predict_one(x, self.root) for x in X])\n\n    def _predict_one(self, x, node):\n        if node.left is None and node.right is None:\n            return node.predicted_class\n        if x[node.feature_index] < node.threshold:\n            return self._predict_one(x, node.left)\n        else:\n            return self._predict_one(x, node.right)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:13:30.616243Z","iopub.execute_input":"2025-04-18T16:13:30.616583Z","iopub.status.idle":"2025-04-18T16:13:30.624410Z","shell.execute_reply.started":"2025-04-18T16:13:30.616558Z","shell.execute_reply":"2025-04-18T16:13:30.623209Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# test the code","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:16:31.526027Z","iopub.execute_input":"2025-04-18T16:16:31.526635Z","iopub.status.idle":"2025-04-18T16:16:31.532167Z","shell.execute_reply.started":"2025-04-18T16:16:31.526591Z","shell.execute_reply":"2025-04-18T16:16:31.530943Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#load the dataset\n\niris = load_iris()\nX= iris.data\ny= iris.target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:17:45.629827Z","iopub.execute_input":"2025-04-18T16:17:45.630186Z","iopub.status.idle":"2025-04-18T16:17:45.637723Z","shell.execute_reply.started":"2025-04-18T16:17:45.630159Z","shell.execute_reply":"2025-04-18T16:17:45.636768Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#split the dataset into train and test\nX_train ,X_test , y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:19:00.854661Z","iopub.execute_input":"2025-04-18T16:19:00.855129Z","iopub.status.idle":"2025-04-18T16:19:00.863822Z","shell.execute_reply.started":"2025-04-18T16:19:00.855097Z","shell.execute_reply":"2025-04-18T16:19:00.862867Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"tree = DecisionTreeClassifier(max_depth=5)\ntree.fit(X_train, y_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:24:23.553710Z","iopub.execute_input":"2025-04-18T16:24:23.554680Z","iopub.status.idle":"2025-04-18T16:24:23.562533Z","shell.execute_reply.started":"2025-04-18T16:24:23.554646Z","shell.execute_reply":"2025-04-18T16:24:23.561581Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<__main__.DecisionTreeClassifier at 0x7e6f3ee39490>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"y_preds = tree.predict(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:24:25.522358Z","iopub.execute_input":"2025-04-18T16:24:25.523676Z","iopub.status.idle":"2025-04-18T16:24:25.528113Z","shell.execute_reply.started":"2025-04-18T16:24:25.523636Z","shell.execute_reply":"2025-04-18T16:24:25.527047Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_preds)\nprint(f'Accuracy : {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:24:27.767069Z","iopub.execute_input":"2025-04-18T16:24:27.767437Z","iopub.status.idle":"2025-04-18T16:24:27.774222Z","shell.execute_reply.started":"2025-04-18T16:24:27.767401Z","shell.execute_reply":"2025-04-18T16:24:27.773207Z"}},"outputs":[{"name":"stdout","text":"Accuracy : 0.3\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}